# MD Gateway 共享内存快照（SeqLock）设计

> 范围说明：本项目聚焦 **进程间通信（IPC）** 与 **框架/接口**，不展开具体业务代码实现。  
> 核心目标：`md_gateway` 唯一登录 TDF，把行情“最新快照”写入共享内存；`trade_app` 只读共享内存做决策与交易。

---

## 1. 进程划分与职责（必须写清）

### md_gateway（唯一 TDF 进程）

#### 流程逻辑：
1.  **加载配置**：读取合约列表（e.g., 5000 个 symbol）。
2.  **建立映射**：在内存中构建 `Map<String, Int>`。
    *   `600000.SH` -> `0`
    *   `000001.SZ` -> `1`
    *   ...
3.  **计算 Size**：按 header 的 offset 约定计算总大小（对齐到 cacheline）：
    - `header_bytes = align_up(sizeof(ShmHeader), 64)`
    - `symbol_dir_bytes = align_up(symbol_count * 16, 64)`（可选，id->wind_code，每项 16B）
    - `snapshot_bytes = symbol_count * sizeof(SnapshotEntry)`
    - `TotalSize = header_bytes + symbol_dir_bytes + snapshot_bytes`
4.  **创建 SHM**：`shm_open` + `ftruncate(TotalSize)` + `mmap`。
5.  **启动 TDF**：根据列表发起订阅。

6. 将回调行情写入共享内存 `entries[symbol_id].payload`（SeqLock odd/even 协议）
7. 周期刷新 `header.heartbeat_ns`，并维护 `md_status/last_err/last_md_ns`
8. （可选）进程内 SPSC ring：回调线程只入队 `symbol_id`（或“指向临时缓冲的指针/索引”），由 writer 线程批量写 shm，确保 **单写者**

### trade_app（不连接 TDF）

- 打开（mmap）共享内存，校验 `magic/abi_version/bytes/endian`
- 策略循环（每秒/每 3 秒）：按 `symbol_id` 读取关注标的的最新快照（SeqLock）
- 监控健康与重启：
  - heartbeat 超时：策略降级（暂停策略/禁止下单/仅撤单/仅平仓，按业务选择）
  - writer 重启：`writer_start_ns` 变化 → 触发重同步（重开 shm/重建映射/重置缓存）
- 交易调用保持串行化（保留现有 queued trading 设计，避免多线程调用交易 SDK）

---

## 2. 高层架构（ASCII）

```
                         (in-process)                      (inter-process)
  +-------------------+  optional SPSC  +-----------------+  shm snapshot   +------------------+
  | TDF SDK callback  |  ------------>  | gateway writer  |  ------------>  | trade_app(s)     |
  | (recv tick)       |  symbol_id/...  | (batch flush)   |  entries[3000]  | read snapshots   |
  +-------------------+                 +-----------------+                 +------------------+
```

> 说明：此阶段采用“快照表”而非“事件 ring”。trade_app 读取的是“最新状态”，天然适配“循环型策略”。

---

## 3. 共享内存布局（Header 字段清单 + SnapshotEntry 格式）（必须写清）

### 3.1 总体布局

```
[ ShmHeader | (optional) symbol_dir | SnapshotEntry entries[symbol_count] | (optional) event_ring ]
```

说明：

- **以 offset 为准**：读写两端必须通过 `header.symbol_dir_offset/symbol_dir_bytes` 与 `header.snapshot_offset/snapshot_bytes` 定位区域，而不是假设固定顺序。
- **当前实现**（对应最新代码）：`symbol_dir` 放在 `ShmHeader` 后、`entries` 前：`snapshot_offset = align_up(sizeof(ShmHeader),64) + symbol_dir_bytes`。
- **基线要求**：只要 `Header + entries[]` 即可工作；当 `symbol_dir` 缺失时设置 `symbol_dir_offset=0/symbol_dir_bytes=0`，读端应退回到“配置 CSV 顺序映射”或其它映射方案。

### 3.2 Header 字段清单（以 `gate_result/header.h` 为基准）

必须字段（读写两端依赖）：

- ABI 校验：`magic[8]`, `abi_version`, `header_bytes`, `total_bytes`, `endian`
- writer 生命周期：`writer_pid`, `writer_start_ns`（充当 epoch）
- 健康检查：`heartbeat_ns`
- 快照区定位：`symbol_count(=3000)`, `snapshot_offset`, `snapshot_bytes`,
  `snapshot_entry_bytes`, `snapshot_payload_bytes(=320)`, `snapshot_mode`
- 状态：`md_status`, `last_err`, `last_md_ns`

可选/扩展字段（建议保留）：

- 符号目录：`symbol_dir_offset`, `symbol_dir_bytes`, `symbol_key_type`
- 双缓冲整表（可选替代 SeqLock）：`global_version`, `snapshot_buf0_offset`, `snapshot_buf1_offset`, `active_buf`
- 事件 ring（未来逐笔/委托/成交）：`event_ring_offset`, `event_ring_bytes`, `event_slot_bytes`, `event_capacity`, `event_write_seq`

### 3.3 SnapshotEntry 格式（快照表条目）

你已确认 `MarketData` 对齐后大小为 **320B**。

- `seq`：odd/even seqlock 计数（建议 `uint32_t`；如担心 wrap 可用 `uint64_t`）
- `payload`：`MarketData(320B)`
- `padding/meta`：将 payload 起始对齐到 64B，减少 false sharing

推荐尺寸（便于推算内存）：

- `SnapshotEntry = 64B(meta/seq/pad) + 320B(payload) = 384B`
- entries 总量：`3000 * 384B ≈ 1.10MB`

---

## 4. 读写协议：SeqLock（odd/even）（必须写清）

### 4.1 写端（md_gateway：单写者）

约定：`seq` 为奇数表示“写入中”，偶数表示“稳定可读”。

伪代码：

```
// begin: make seq odd
seq++
// write payload (320B) + meta
memcpy(payload, src, 320)
// end: publish stable (even)
seq++
```

内存序：最后一次把 seq 变成 even 的写入需要是 release；读端 seq load 需要 acquire。

### 4.2 读端（trade_app：多读者）

伪代码：

```
loop:
  s1 = load(seq)      // acquire
  if (s1 is odd) continue
  memcpy(local, payload, 320)
  s2 = load(seq)      // acquire
  if (s1 == s2) break // success
```

读失败策略：

- 读端可设置“最大重试次数/最大自旋时间”
- 超出阈值视为数据不可用（返回空/沿用上次快照/触发降级）

> 单写者约束：SeqLock 不支持多个线程同时写同一个 entry。若 TDF 回调可能多线程，必须用（可选）SPSC/MPSC 把写入集中到 writer 线程，或改用“双缓冲 entry”方案。

---

## 5. 启动顺序（必须写清）

### 5.1 md_gateway 启动（推荐顺序）

1. 读 config（TDF 登录信息 + 订阅 CSV 路径）
2. 解析 CSV，建立 `wind_code -> symbol_id`（并固定 `symbol_count=3000` 的占位策略：不足补空、超出报错）
3. 创建共享内存并初始化：
   - 写入 `magic/version/offset/bytes`
   - 初始化 entries 的 `seq=0`（全 even）
   - 写入 `writer_start_ns`（epoch）
4. 连接 TDF，开始接收回调
5. 刷新 `heartbeat_ns`、更新 `last_md_ns`

### 5.2 trade_app 启动

1. 尝试打开共享内存：
   - 若不存在：等待/退出（按业务选择）
   - 若存在：校验 `magic/abi_version/header_bytes/total_bytes/endian`
2. 读取 `writer_start_ns/heartbeat_ns`：
   - heartbeat 为 0 或超时：先进入“禁交易/等待恢复”状态
3. 进入策略循环：读取关注 symbol 的快照（SeqLock）

> 建议：trade_app **mmap 一次常驻**；只有在检测到 writer 重启（epoch 变化）或 shm 失效时才重新 open/mmap。每秒 mmap/munmap 会引入系统调用抖动。

---

## 6. 故障语义与降级（必须写清）

### 6.1 heartbeat 超时（gateway 活性异常）

trade_app 处理建议：

- 立即停止产生新订单（禁止下单/禁止加仓）
- 可选：只允许撤单或只允许风控平仓
- 周期性重试（等待 heartbeat 恢复）

### 6.2 gateway 重启（epoch 变化）

判定条件：

- `header.writer_start_ns` 变化（或 `magic/version` 变化）

trade_app 行为：

- 清空/重建本地行情缓存（必要时重建 wind_code->id 映射）
- 重新校验 shm header 与 entry_bytes
- 恢复策略前先等待 heartbeat 正常

### 6.3 TDF 断线/重连

gateway 行为建议：

- 设置 `md_status=DISCONNECTED/RECONNECTING`，并更新 `last_err`
- heartbeat **仍然持续刷新**（表示 gateway 进程仍在），同时 `last_md_ns` 不再更新

trade_app 行为建议：

- 若 `md_status != OK`：进入禁交易或降级模式（由业务决定）

---

## 7. 模块拆分（框架搭建清单）

> 这里是“工程结构/接口”拆分，便于后续用 CLI 分任务落地；不要求本阶段实现完整逻辑。

- 新增可执行程序：`md_gateway`
  - 复用/迁移现有 `TdfMarketDataApi` 的连接与回调入口
  - 回调不再写进程内 `std::map + mutex` 缓存；改为写共享内存快照表（SeqLock）或入队到 SPSC

- 新增共享内存模块（接口层）
  - writer：create/init shm、写 `SnapshotEntry`
  - reader：open/validate shm、读 `SnapshotEntry`
  - ABI/结构体：`ShmHeader`、`SnapshotEntry`（字段固定、可版本化）

- trade_app 新增“行情适配器”
  - `ShmMarketDataApi`：对外提供 `get_snapshot(symbol)` / `get_snapshot(symbol_id)`
  - 内部使用 SeqLock 从 shm 读取
  - trade_app `main` 中把原 `TdfMarketDataApi::connect()` 替换为 `ShmMarketDataApi::connect()`（实质是 open shm）

---

## 8. 设计取舍（为什么是快照表 + SeqLock）

- 快照表适合“策略循环只需要最新状态”的模式：读 O(1)，无需追事件序列
- SeqLock 对单写多读开销极低：一个计数 + 一次 memcpy
- 未来若要逐笔/事件驱动：在 header 里预留 event ring 区域即可，不破坏现有 ABI
